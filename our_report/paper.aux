\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Music Task}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Data description}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Data visualization and cleaning}{1}{subsection.1.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dist_classification}{{1a}{1}{Mean and standard deviation for the training data features. The input is not normalised and contains outliers.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:dist_classification}{{a}{1}{Mean and standard deviation for the training data features. The input is not normalised and contains outliers.\relax }{figure.caption.1}{}}
\newlabel{fig:Lambda_pLr}{{1b}{1}{Train and test error assessment with penalty factor ($\lambda $) for penalized logistic regression for 50-50 split.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:Lambda_pLr}{{b}{1}{Train and test error assessment with penalty factor ($\lambda $) for penalized logistic regression for 50-50 split.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Logistic Regression}{2}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of logistic regression and penalized logistic regression based on validation accuracy.\relax }}{2}{figure.2}}
\newlabel{fig:comp_LR_pLR}{{2}{2}{Comparison of logistic regression and penalized logistic regression based on validation accuracy.\relax }{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Best predicted error estimates for the test data.\relax }}{2}{table.1}}
\newlabel{table:test_errors}{{1}{2}{Best predicted error estimates for the test data.\relax }{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Feature transformation}{2}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Summary}{2}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}People Task}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Description}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Data visualization and cleaning}{3}{subsection.2.2}}
\newlabel{fig:dist_regression}{{3a}{3}{Mean and standard deviation for the first 36 real valued variables of Xtrain. The input is not normalised and feature 36 is the only negative one.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:dist_regression}{{a}{3}{Mean and standard deviation for the first 36 real valued variables of Xtrain. The input is not normalised and feature 36 is the only negative one.\relax }{figure.caption.2}{}}
\newlabel{fig:feature36}{{3b}{3}{Feature 36 versus output values. X = 1.4 (black line) and y = 4900 (red line) provide a good separation of the two blobs.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:feature36}{{b}{3}{Feature 36 versus output values. X = 1.4 (black line) and y = 4900 (red line) provide a good separation of the two blobs.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Data visualization\relax }}{3}{figure.caption.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Regression baseline methods}{3}{subsection.2.3}}
\newlabel{fig:alpha1}{{4a}{4}{Results for the big blob.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:alpha1}{{a}{4}{Results for the big blob.\relax }{figure.caption.3}{}}
\newlabel{fig:alpha2}{{4b}{4}{Results for small blob.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:alpha2}{{b}{4}{Results for small blob.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces RMSE produced for 50 values of $\alpha $ ranging between $10^{-3}$ and 0.2. Results refer to both b fitted by least squares using gradient descent.\relax }}{4}{figure.caption.3}}
\newlabel{fig:lambda1}{{5a}{4}{Results for the big blob.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lambda1}{{a}{4}{Results for the big blob.\relax }{figure.caption.4}{}}
\newlabel{fig:lambda2}{{5b}{4}{Results for small blob.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lambda2}{{b}{4}{Results for small blob.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces RMSE produced for 1000 values of $\lambda $ ranging between $10^{-7}$ and 0.1. Results refer to both models fitted by ridge regression.\relax }}{4}{figure.caption.4}}
\newlabel{fig:learning_curve}{{\caption@xref {fig:learning_curve}{ on input line 81}}{5}{Regression baseline methods}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Learning curve produced for our model using ridge regression. The blue lines represents the train RMSE and the red the test RMSE. Moreover, the top figure represents the big blob and the bottom figure the small blob.\relax }}{5}{figure.caption.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feature transformations}{5}{subsection.2.4}}
\newlabel{table:feat_transform}{{2.4}{5}{Feature transformations}{figure.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Estimated Train and Test RMSE for the two blob models.\relax }}{5}{table.2}}
\newlabel{fig:degree_blob1}{{7a}{6}{First Blob. Mean RMSE for training set \newline (blue curve) and testing (red curve) versus poly-\newline nomial degree. The errors were computed using\newline 5-fold cross-validation.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:degree_blob1}{{a}{6}{First Blob. Mean RMSE for training set \newline (blue curve) and testing (red curve) versus poly-\newline nomial degree. The errors were computed using\newline 5-fold cross-validation.\relax }{figure.caption.6}{}}
\newlabel{fig:degre_blob2}{{7b}{6}{Second Blob. Mean RMSE for training set (blue curve) and testing (red curve) versus polynomial degree. The errors were computed using 5-fold cross-validation.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:degre_blob2}{{b}{6}{Second Blob. Mean RMSE for training set (blue curve) and testing (red curve) versus polynomial degree. The errors were computed using 5-fold cross-validation.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Selection of polynomial degree\relax }}{6}{figure.caption.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Summary}{6}{subsection.2.5}}
